
# Building a Grammatical Error Correction Model

This project aims to develop an advanced grammar correction system utilizing a T5-based model, a powerful transformer architecture. The system is trained on a substantial dataset containing pairs of sentences with both correct and incorrect grammar. The training process encompasses essential steps such as tokenization, data preprocessing, and fine-tuning the T5 model for the specific task of sequence-to-sequence grammar correction.
# CONTENT
The primary dataset utilized in this project is C4_200M.tsv, a substantial corpus containing pairs of sentences with correct and incorrect grammar. This dataset is a segment of the C4 (Common Crawl) dataset, offering a diverse range of sentences sourced from web crawls. The dataset size is considerable, with approximately 18.4 million rows.
# DATASET LINK FROM KAGGLE
https://www.kaggle.com/datasets/dariocioni/c4200m
# REFERENCES
- Junczys-Dowmunt, M., et al. (2018). Approaching Neural Grammatical Error Correction as a Low-Resource Machine Translation Task. NAACL-HLT.https://aclanthology.org/N18-1055/
- Xie, Z., et al. (2016). Neural Language Correction with Character-Based Attention. arXiv preprint arXiv:1603.09727. https://arxiv.org/abs/1603.09727
- Christopher Bryant, Mariano Felice, Øistein E. Andersen, and Ted Briscoe. 2019. The BEA- 2019 shared task on grammaBcal error correcBon. In Proceedings of the Fourteenth Workshop on InnovaBve Use of NLP for Building EducaBonal ApplicaBons, pages 52–75 https://aclanthology.org/W19-4406/
- Shamil Chollampatt and Hwee Tou Ng. 2018a. A multilayer convolutional encoder- decoder neural network for grammatical error correction. In Proceedings of the Thirty- Second AAAI Conference on Artificial Intelligence. https://ojs.aaai.org/index.php/AAAI/article/view/12069
- Daniel Dahlmeier and Hwee Tou Ng. 2012. Better evaluation for grammatical error correction. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 568- 572. https://aclanthology.org/N12-1067/
- Tao Ge, Furu Wei, and Ming Zhou. 2018. Fluency boost learning and inference for neural grammatical error correction. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1055–1065. https://aclanthology.org/P18-1097/

